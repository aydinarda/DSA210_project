{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429 {\n",
      "    \"error\": {\n",
      "        \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\",\n",
      "        \"type\": \"insufficient_quota\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"insufficient_quota\"\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single email (first row for testing purposes)\n",
    "email_row = enhanced_classified_emails.iloc[6]\n",
    "\n",
    "# Extract the topic from the email\n",
    "topic = email_row['topic']\n",
    "\n",
    "# Fetch corresponding stats for the topic from the topic summary\n",
    "stats = topic_summary.loc[topic_summary['topic'] == topic]\n",
    "\n",
    "# Check if stats exist for the given topic\n",
    "if stats.empty:\n",
    "    print(f\"No stats found for topic: {topic}\")\n",
    "else:\n",
    "    # Extract statistics as a dictionary for prompt generation\n",
    "    stats_dict = {\n",
    "        'topic': topic,\n",
    "        'average_word_count': stats['avg_word_count'].values[6],\n",
    "        'std_word_count': stats['std_word_count'].values[6],\n",
    "        'average_body_length': stats['avg_body_length'].values[6],\n",
    "        'std_body_length': stats['std_body_length'].values[6],\n",
    "        'average_hour': stats['avg_hour'].values[6],\n",
    "        'std_hour': stats['std_hour'].values[6],\n",
    "        'formality_average': stats['avg_formality_ratio'].values[6],\n",
    "        'formality_std': stats['std_formality_ratio'].values[6]\n",
    "    }\n",
    "\n",
    "    # Generate a GPT prompt based on the single email and topic stats\n",
    "    prompt = (\n",
    "        f\"Write an email similar to the following example:\\n\\n\"\n",
    "        f\"Subject: {email_row['subject']}\\n\\n\"\n",
    "        f\"Here are the average characteristics of emails for the topic '{stats_dict['topic']}':\\n\"\n",
    "        f\"- Average word count: {stats_dict['average_word_count']} (±{stats_dict['std_word_count']})\\n\"\n",
    "        f\"- Average body length: {stats_dict['average_body_length']} (±{stats_dict['std_body_length']})\\n\"\n",
    "        f\"- Average hour sent: {stats_dict['average_hour']} (±{stats_dict['std_hour']})\\n\"\n",
    "        f\"- Formality score: {stats_dict['formality_average']} (±{stats_dict['formality_std']})\\n\\n\"\n",
    "        f\"Use a semi-formal tone. The email should match the given characteristics.\"\n",
    "    )\n",
    "\n",
    "    # Display the generated prompt\n",
    "    prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Processed row index 1. Saved the result to 'gpt_output_single.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "# 1. Load your data\n",
    "enhanced_classified_emails = pd.read_csv(\"enhanced_classified_emails.csv\")\n",
    "topic_summary = pd.read_excel(\"topic_summary_no_outliers_IQR.xlsx\")\n",
    "\n",
    "# 2. Define a helper function to call ChatGPT API\n",
    "def call_chatgpt_api(prompt, api_key):\n",
    "    \"\"\"\n",
    "    Send a single prompt to the ChatGPT API and return the response text.\n",
    "    Each call is effectively a new 'session' unless you pass conversation history.\n",
    "    \"\"\"\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",  # or 'gpt-3.5-turbo' if you prefer\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are writing emails using statistics (but do not include them in the mail). \"\n",
    "                    \"Do not give numbers or direct data, but write an email regarding the subject. \"\n",
    "                    \"Use a semi-formal tone. \"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "# 3. Prepare to store results\n",
    "all_results = []\n",
    "\n",
    "# 4. Choose a single row index to process (e.g., index 5)\n",
    "idx_to_test = 1\n",
    "\n",
    "# 5. Fetch the row\n",
    "email_row = enhanced_classified_emails.iloc[idx_to_test]\n",
    "topic = email_row['topic']\n",
    "subject_text = str(email_row.get('subject', ''))\n",
    "body_text = str(email_row.get('body', ''))\n",
    "\n",
    "# Default placeholders\n",
    "prompt = \"\"\n",
    "gpt_response = None\n",
    "\n",
    "# 6. Check the skip conditions\n",
    "if topic == \"Empty\":\n",
    "    # If topic is \"Empty,\" skip generating an email\n",
    "    prompt = \"Skipped because topic is 'Empty'.\"\n",
    "elif \"QXJkYSBB\" in subject_text or \"QXJkYSBB\" in body_text:\n",
    "    # Skip if the forbidden string is in the subject or body\n",
    "    prompt = \"Skipped because 'QXJkYSBB' substring was found in subject or body.\"\n",
    "else:\n",
    "    # 7. Fetch stats for this topic from topic_summary\n",
    "    stats = topic_summary.loc[topic_summary['topic'] == topic]\n",
    "    \n",
    "    if stats.empty:\n",
    "        # No stats found, skip the API\n",
    "        prompt = f\"No stats found for topic: {topic}\"\n",
    "        gpt_response = None\n",
    "    else:\n",
    "        # Build the stats_dict (ensure column names match your topic_summary)\n",
    "        stats_dict = {\n",
    "            'topic': topic,\n",
    "            'average_word_count':       stats['avg_word_count'].values[0],\n",
    "            'std_word_count':           stats['std_word_count'].values[0],\n",
    "            'average_body_length':      stats['avg_body_length'].values[0],\n",
    "            'std_body_length':          stats['std_body_length'].values[0],\n",
    "            'average_hour':             stats['avg_hour'].values[0],\n",
    "            'std_hour':                 stats['std_hour'].values[0],\n",
    "            'formality_average':        stats['avg_formality_ratio'].values[0],\n",
    "            'formality_std':            stats['std_formality_ratio'].values[0]\n",
    "        }\n",
    "\n",
    "        # 8. Generate the GPT prompt\n",
    "        prompt = (\n",
    "            f\"Write an email similar to the following example:\\n\\n\"\n",
    "            f\"Subject: {subject_text}\\n\\n\"\n",
    "            f\"Here are the average characteristics of emails for the topic '{stats_dict['topic']}':\\n\"\n",
    "            f\"- Average word count: {stats_dict['average_word_count']} (±{stats_dict['std_word_count']})\\n\"\n",
    "            f\"- Average body length: {stats_dict['average_body_length']} (±{stats_dict['std_body_length']})\\n\"\n",
    "            f\"- Average hour sent: {stats_dict['average_hour']} (±{stats_dict['std_hour']})\\n\"\n",
    "            f\"- Formality score: {stats_dict['formality_average']} (±{stats_dict['formality_std']})\\n\\n\"\n",
    "            f\"Do NOT use these statistics or direct numbers in the final email. \"\n",
    "            f\"Write it as if it's real life.\"\n",
    "        )\n",
    "\n",
    "        # 9. Call the ChatGPT API\n",
    "        openai_api_key = \"sk-***********zD5YPT_xXhHRXXiHtyy4iMZgywbT3BlbkFJxnLBjxWDh22cjl-ISWIvhD1HEBOTWwR5neJFfpsj8A\"  # This key is deactivated\n",
    "        gpt_response = call_chatgpt_api(prompt, openai_api_key)\n",
    "\n",
    "# 10. Append results for this single row\n",
    "all_results.append({\n",
    "    'row_index': idx_to_test,\n",
    "    'topic': topic,\n",
    "    'subject': subject_text,\n",
    "    'original_body': body_text,\n",
    "    'prompt_used': prompt,\n",
    "    'gpt_generated_body': gpt_response\n",
    "})\n",
    "\n",
    "# 11. Convert all_results to a DataFrame and save to Excel\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_excel(\"gpt_output_single.xlsx\", index=False)\n",
    "\n",
    "print(f\"Done! Processed row index {idx_to_test}. Saved the result to 'gpt_output_single.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Processed all rows in 'enhanced_classified_emails.csv' and saved the results to 'gpt_output_all.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# 1. Load your data\n",
    "enhanced_classified_emails = pd.read_csv(\"enhanced_classified_emails.csv\")\n",
    "topic_summary = pd.read_excel(\"topic_summary_no_outliers_IQR.xlsx\")\n",
    "\n",
    "# 2. Define a helper function to call ChatGPT API\n",
    "def call_chatgpt_api(prompt, api_key):\n",
    "    \"\"\"\n",
    "    Send a single prompt to the ChatGPT API and return the response text.\n",
    "    Each call is effectively a new 'session' unless you pass conversation history.\n",
    "    \"\"\"\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",  # or 'gpt-3.5-turbo' if you prefer\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are writing emails using statistics (but do not include them in the mail). \"\n",
    "                    \"Do not give numbers or direct data, but write an email regarding the subject. \"\n",
    "                    \"Use a semi-formal tone.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "# 3. Prepare to store results\n",
    "all_results = []\n",
    "\n",
    "# 4. Iterate over all rows in enhanced_classified_emails\n",
    "for idx in range(len(enhanced_classified_emails)):\n",
    "    email_row = enhanced_classified_emails.iloc[idx]\n",
    "    topic = email_row['topic']\n",
    "    subject_text = str(email_row.get('subject', ''))\n",
    "    body_text = str(email_row.get('body', ''))\n",
    "\n",
    "    prompt = \"\"\n",
    "    gpt_response = None\n",
    "\n",
    "    # A) Skip if topic == \"Empty\"\n",
    "    if topic == \"Empty\":\n",
    "        prompt = \"Skipped because topic is 'Empty'.\"\n",
    "        # gpt_response remains None\n",
    "    # B) Skip if \"QXJkYSBB\" found in subject or body\n",
    "    elif \"QXJkYSBB\" in subject_text or \"QXJkYSBB\" in body_text:\n",
    "        prompt = \"Skipped because 'QXJkYSBB' substring was found in subject or body.\"\n",
    "    else:\n",
    "        # C) Otherwise, fetch stats for this topic\n",
    "        stats = topic_summary.loc[topic_summary['topic'] == topic]\n",
    "\n",
    "        if stats.empty:\n",
    "            prompt = f\"No stats found for topic: {topic}\"\n",
    "        else:\n",
    "            # Build the stats_dict (ensure these column names match your topic_summary)\n",
    "            stats_dict = {\n",
    "                'topic': topic,\n",
    "                'average_word_count':       stats['avg_word_count'].values[0],\n",
    "                'std_word_count':           stats['std_word_count'].values[0],\n",
    "                'average_body_length':      stats['avg_body_length'].values[0],\n",
    "                'std_body_length':          stats['std_body_length'].values[0],\n",
    "                'average_hour':             stats['avg_hour'].values[0],\n",
    "                'std_hour':                 stats['std_hour'].values[0],\n",
    "                'formality_average':        stats['avg_formality_ratio'].values[0],\n",
    "                'formality_std':            stats['std_formality_ratio'].values[0]\n",
    "            }\n",
    "\n",
    "            # Generate the GPT prompt\n",
    "            prompt = (\n",
    "                f\"Write an email similar to the following example:\\n\\n\"\n",
    "                f\"Subject: {subject_text}\\n\\n\"\n",
    "                f\"Here are the average characteristics of emails for the topic '{stats_dict['topic']}':\\n\"\n",
    "                f\"- Average word count: {stats_dict['average_word_count']} (±{stats_dict['std_word_count']})\\n\"\n",
    "                f\"- Average body length: {stats_dict['average_body_length']} (±{stats_dict['std_body_length']})\\n\"\n",
    "                f\"- Average hour sent: {stats_dict['average_hour']} (±{stats_dict['std_hour']})\\n\"\n",
    "                f\"- Formality score: {stats_dict['formality_average']} (±{stats_dict['formality_std']})\\n\\n\"\n",
    "                f\"Do NOT use these statistics or direct numbers in the final email. \"\n",
    "                f\"Write it as if it's real life.\"\n",
    "            )\n",
    "\n",
    "            # Call the ChatGPT API\n",
    "            openai_api_key = \"sk-***********zD5YPT_xXhHRXXiHtyy4iMZgywbT3BlbkFJxnLBjxWDh22cjl-ISWIvhD1HEBOTWwR5neJFfpsj8A\"  # This key is deactivated\n",
    "            gpt_response = call_chatgpt_api(prompt, openai_api_key)\n",
    "\n",
    "    # Save the results for this row\n",
    "    all_results.append({\n",
    "        'row_index': idx,\n",
    "        'topic': topic,\n",
    "        'subject': subject_text,\n",
    "        'original_body': body_text,\n",
    "        'prompt_used': prompt,\n",
    "        'gpt_generated_body': gpt_response\n",
    "    })\n",
    "\n",
    "# 5. Convert all_results to a DataFrame and save to Excel\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_excel(\"gpt_output_all.xlsx\", index=False)\n",
    "\n",
    "print(\"Done! Processed all rows in 'enhanced_classified_emails.csv' and saved the results to 'gpt_output_all.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Processed all rows in 'enhanced_classified_emails.csv' and saved the results to 'gpt_output_all.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# 5. Convert all_results to a DataFrame and save to Excel\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_excel(\"gpt_output_all.xlsx\", index=False)\n",
    "\n",
    "print(\"Done! Processed all rows in 'enhanced_classified_emails.csv' and saved the results to 'gpt_output_all.xlsx'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
